{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e989c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a574126",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a36112",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d5565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1430f23",
   "metadata": {},
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3433fd",
   "metadata": {},
   "source": [
    "##### raw/config.yaml"
   ]
  },
  {
   "cell_type": "raw",
   "id": "658087ed",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "ROOT_DIR: artifacts \n",
    "\n",
    "STRUCTURED_TRAINING:\n",
    "    ROOT_DIR: data\n",
    "\n",
    "DATA: \n",
    "    ROOT_DIR: data \n",
    "\n",
    "    INGESTION: \n",
    "        ROOT_DIR: ingestion \n",
    "        RAW_DATA_DIR: raw \n",
    "        OUTPUT_DIR: output \n",
    "        \n",
    "    TRANSFORMATION: \n",
    "        ROOT_DIR: transformation \n",
    "        PARSED_DATA_DIR: parsed \n",
    "        STRUCTURED_DATA_DIR: structured \n",
    "        OUTPUT_DIR: output\n",
    "\n",
    "JD:\n",
    "    ROOT_DIR: job\n",
    "\n",
    "SCORINGS:\n",
    "    ROOT_DIR: scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5be58c",
   "metadata": {},
   "source": [
    "# constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0a230d",
   "metadata": {},
   "source": [
    "##### schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d977fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update __all__ \n",
    "\n",
    "from pydantic import BaseModel, Field \n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class Constants:\n",
    "    ...\n",
    "\n",
    "class DataIngestionConstants(BaseModel):\n",
    "    TIME_STAMP: datetime\n",
    "    ROOT_DIR_NAME: str = Field(frozen=True) \n",
    "    DATA_ROOT_DIR_NAME: str = Field(frozen=True) \n",
    "    INGESTION_ROOT_DIR_NAME: str = Field(frozen=True) \n",
    "    RAW_DATA_DIR_NAME: str = Field(frozen=True)\n",
    "    OUTPUT_DIR_NAME: str = Field(frozen=True)\n",
    "\n",
    "class DataTransformationConstants(BaseModel):\n",
    "    PROMPT: str\n",
    "    TIME_STAMP: datetime\n",
    "    ROOT_DIR_NAME: str = Field(frozen=True) \n",
    "    DATA_ROOT_DIR_NAME: str = Field(frozen=True) \n",
    "    TRANSFORMATION_ROOT_DIR_NAME: str = Field(frozen=True) \n",
    "    PARSED_DATA_DIR_NAME: str = Field(frozen=True)\n",
    "    STRUCTURED_DATA_DIR_NAME: str = Field(frozen=True)\n",
    "    TRAIN_DATA_DIR_NAME: str = Field(frozen=True)\n",
    "    OUTPUT_DIR_NAME: str = Field(frozen=True)\n",
    "\n",
    "class JobDescriptionConstants(BaseModel):\n",
    "    TIME_STAMP: datetime\n",
    "    ROOT_DIR_NAME: str = Field(frozen=True) \n",
    "    JD_ROOT_DIR_NAME: str = Field(frozen=True) \n",
    "\n",
    "class ScoringConstants(BaseModel):\n",
    "    ROOT_DIR_NAME: str = Field(frozen=True)\n",
    "    SCORES_ROOT_DIR_NAME: str = Field(frozen=True)\n",
    "\n",
    "__all__ = [\"DataIngestionConstants\", \"DataTransformationConstants\", \"Constants\", \"JobDescriptionConstants\", \"ScoringConstants\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab053194",
   "metadata": {},
   "source": [
    "##### values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df8e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ats.exception import CustomException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e217d178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 things needed to be updated at a time [avl_cons, process, Note: Available name] \n",
    "# Note is inside docstring of function 'load' from this file and 'load_constants' inside __int__.py \n",
    "# update __all__ \n",
    "\n",
    "# from .schema import *\n",
    "# from ..exception import CustomException \n",
    "from typing import List, Tuple, Dict\n",
    "from datetime import datetime\n",
    "from box import ConfigBox\n",
    "import sys \n",
    "\n",
    "\n",
    "def __ing__(CONFIG:ConfigBox) -> Constants:\n",
    "    return DataIngestionConstants(\n",
    "        TIME_STAMP = datetime.now(),\n",
    "        ROOT_DIR_NAME = CONFIG.ROOT_DIR, \n",
    "        DATA_ROOT_DIR_NAME = CONFIG.DATA.ROOT_DIR, \n",
    "        INGESTION_ROOT_DIR_NAME = CONFIG.DATA.INGESTION.ROOT_DIR, \n",
    "        RAW_DATA_DIR_NAME = CONFIG.DATA.INGESTION.RAW_DATA_DIR,\n",
    "        OUTPUT_DIR_NAME = CONFIG.DATA.INGESTION.OUTPUT_DIR\n",
    "    )\n",
    "\n",
    "def __transform__(CONFIG:ConfigBox) -> Constants:\n",
    "    return DataTransformationConstants(\n",
    "        PROMPT = \"\"\"\n",
    "        You are a data structuring assistant. Extract and structure ONLY the information explicitly provided in the input data.\n",
    "\n",
    "        IMPORTANT RULES:\n",
    "        1. Extract ONLY information that is explicitly present in the data\n",
    "        2. Do NOT add, infer, or generate any information\n",
    "        3. If information is missing, leave fields as null/None\n",
    "        4. For dates, use the exact format provided (e.g., \"March 2019\", \"Present\")\n",
    "        5. For lists, only include items explicitly mentioned\n",
    "\n",
    "        Input data to structure:\n",
    "        {input_data}\n",
    "        \"\"\", \n",
    "        TIME_STAMP = datetime.now(),\n",
    "        ROOT_DIR_NAME = CONFIG.ROOT_DIR , \n",
    "        DATA_ROOT_DIR_NAME = CONFIG.DATA.ROOT_DIR , \n",
    "        TRANSFORMATION_ROOT_DIR_NAME = CONFIG.DATA.TRANSFORMATION.ROOT_DIR , \n",
    "        PARSED_DATA_DIR_NAME = CONFIG.DATA.TRANSFORMATION.PARSED_DATA_DIR ,\n",
    "        STRUCTURED_DATA_DIR_NAME = CONFIG.DATA.TRANSFORMATION.STRUCTURED_DATA_DIR ,\n",
    "        TRAIN_DATA_DIR_NAME = CONFIG.STRUCTURED_TRAINING.ROOT_DIR,\n",
    "        OUTPUT_DIR_NAME = CONFIG.DATA.TRANSFORMATION.OUTPUT_DIR\n",
    "    )\n",
    "\n",
    "def __jd__(CONFIG:ConfigBox) -> Constants:\n",
    "    return JobDescriptionConstants(\n",
    "        TIME_STAMP = datetime.now(),\n",
    "        ROOT_DIR_NAME = CONFIG.ROOT_DIR,\n",
    "        JD_ROOT_DIR_NAME = CONFIG.JD.ROOT_DIR\n",
    "    )\n",
    "\n",
    "def __scoring__(CONFIG:ConfigBox) -> Constants:\n",
    "    return ScoringConstants(\n",
    "        ROOT_DIR_NAME = CONFIG.ROOT_DIR,\n",
    "        SCORES_ROOT_DIR_NAME = CONFIG.SCORINGS.ROOT_DIR\n",
    "    )\n",
    "\n",
    "dataingestion = \"DataIngestion\"\n",
    "datatransformation = \"DataTransformation\"\n",
    "jobdescription = \"JobDescription\"\n",
    "scorings = \"Scoring\"\n",
    "\n",
    "avl_cons = [\n",
    "    dataingestion, \n",
    "    datatransformation, \n",
    "    jobdescription,\n",
    "    scorings\n",
    "]\n",
    "process = {\n",
    "    dataingestion:__ing__,\n",
    "    datatransformation:__transform__,\n",
    "    jobdescription:__jd__,\n",
    "    scorings:__scoring__\n",
    "} \n",
    "\n",
    "def load(config:ConfigBox, name: str | List[str] | Tuple[str]) -> Dict: \n",
    "    \"\"\"loads respective constants for the given name\n",
    "\n",
    "    Args:\n",
    "        config (ConfigBox): configuration for the object\n",
    "        name (str | List[str] | Tuple[str]): name of required object  \n",
    "\n",
    "        Note: Available names --> DataIngestion, DataTransformation, JobDescription, Scoring\n",
    "\n",
    "    Raises:\n",
    "        CustomException: Error shows with file name, line no and error message\n",
    "\n",
    "    Returns:\n",
    "        Dict: key = name of object used to load given in variable \\'name\\', \n",
    "        \n",
    "              value = Object of the name used to load,\n",
    "\n",
    "              example:\n",
    "              output = load(config, \"DataIngestion\")\n",
    "              output = { \"DataIngestion\" : DataIngestionConstants } \n",
    "              data_ingestion_constants = output[\"DataIngestion\"] \n",
    "    \"\"\"\n",
    "    reqs:List[str] = []\n",
    "    try:\n",
    "        # validate type   \n",
    "        if isinstance(name, str):\n",
    "            reqs.append(name) \n",
    "        elif isinstance(name, List) or isinstance(name, Tuple):\n",
    "            reqs += name \n",
    "        else:\n",
    "            ValueError(f\"Unsupported type {{{type(name)}}} for variable {{name}}\") \n",
    "\n",
    "        # validate values \n",
    "        for req in reqs:\n",
    "            if req not in avl_cons:\n",
    "                ValueError(f\"Unknown value provided in variable \\'name\\', {req}, name can only have values from {avl_cons}\") \n",
    "\n",
    "        # run respective functions and return the output \n",
    "        output = {}\n",
    "        for req in reqs: \n",
    "            func = process[req] \n",
    "            output[req] = func(config)\n",
    "\n",
    "        return output\n",
    "    except Exception as e: \n",
    "        raise CustomException(e, sys) \n",
    "    \n",
    "\n",
    "__all__ = [\"load\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c175475",
   "metadata": {},
   "source": [
    "# entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7483ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update __all__ \n",
    "\n",
    "from pydantic import BaseModel\n",
    "from datetime import datetime\n",
    "from pathlib import Path \n",
    "\n",
    "\n",
    "class DataIngestion(BaseModel):\n",
    "    TIME_STAMP: datetime\n",
    "    ROOT_DIR_PATH: Path\n",
    "    DATA_ROOT_DIR_PATH: Path\n",
    "    INGESTION_ROOT_DIR_PATH: Path\n",
    "    RAW_DATA_DIR_PATH: Path\n",
    "    OUTPUT_DIR_PATH: Path\n",
    "\n",
    "class DataTransformation(BaseModel):\n",
    "    PROMPT: str\n",
    "    TIME_STAMP: datetime\n",
    "    ROOT_DIR_PATH: Path\n",
    "    DATA_ROOT_DIR_PATH: Path\n",
    "    TRANSFORMATION_ROOT_DIR_PATH: Path\n",
    "    PARSED_DATA_DIR_PATH: Path\n",
    "    STRUCTURED_DATA_DIR_PATH: Path\n",
    "    TRAIN_DATA_DIR_PATH: Path\n",
    "    OUTPUT_DIR_PATH: Path\n",
    "\n",
    "class JobDescription(BaseModel):\n",
    "    TIME_STAMP: datetime\n",
    "    ROOT_DIR_PATH: Path\n",
    "    JD_ROOT_DIR_PATH: Path\n",
    "\n",
    "class Scoring(BaseModel):\n",
    "    ROOT_DIR_PATH: Path\n",
    "    SCORES_ROOT_DIR_PATH: Path\n",
    "\n",
    "__all__ = [\"DataIngestion\", \"DataTransformation\", \"JobDescription\", \"Scoring\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b79da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ats.components.scorers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80f8c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\n",
    "    \"/home/hasan/Artificial-Intelligence/projects/Resume-ATS-Score-Checker/artifacts/data/transformation/structured/1(1)_pdf.json\"\n",
    "    ) as fp:\n",
    "    resume_data = json.load(fp)\n",
    "with open(\n",
    "    \"/home/hasan/Artificial-Intelligence/projects/Resume-ATS-Score-Checker/artifacts/job/28_09_2025_16_02_13.json\"\n",
    "    ) as fp:\n",
    "    job_data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddd90006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================ RD ================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'personal_info': {'name': 'Michael Brown',\n",
       "  'email': 'michael.brown@example.com',\n",
       "  'phone': '(111) 222-3333',\n",
       "  'location': 'Chicago, IL',\n",
       "  'linkedin': None},\n",
       " 'professional_summary': {'headline': None,\n",
       "  'summary': 'Recent Computer Science graduate with a strong foundation in programming and problem-solving. Eager to contribute to a dynamic team and grow as a software developer.',\n",
       "  'total_experience_years': None,\n",
       "  'career_level': None},\n",
       " 'work_experience': [{'title': 'Software Development Intern',\n",
       "   'company': 'Tech Innovations Ltd.',\n",
       "   'start_date': 'May 2024',\n",
       "   'end_date': 'August 2024',\n",
       "   'duration_months': None,\n",
       "   'responsibilities': ['Assisted in developing and testing software modules using Python.',\n",
       "    'Participated in daily stand-ups and code reviews.',\n",
       "    'Learned about agile development methodologies.'],\n",
       "   'achievements': None,\n",
       "   'technologies_used': ['Python']}],\n",
       " 'skills': {'technical': ['Python'], 'soft': None, 'certifications': None},\n",
       " 'education': [{'degree': 'Bachelor of Science in Computer Science',\n",
       "   'institution': 'State University of Illinois',\n",
       "   'graduation_year': 2024,\n",
       "   'gpa': '3.7/4.0'}],\n",
       " 'keywords': ['Python',\n",
       "  'Object-Oriented Programming',\n",
       "  'Data Structures',\n",
       "  'Algorithms']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"================================================ RD ================================================\")\n",
    "resume_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9bb11ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================ JD ================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'job_title': 'Data Scientist',\n",
       " 'company_name': 'Capgemini',\n",
       " 'location': 'Bengaluru',\n",
       " 'job_type': 'Full Time, Permanent',\n",
       " 'experience_level': '4 - 7 years',\n",
       " 'job_description': 'About The Role\\nThis role involves the development and application of engineering practice and knowledge in the following technologiesStandards and protocols, application software and embedded software for wireless and satellite networks, fixed networks and enterprise networks; connected devices (IOT and device engineering), connected applications (5G/ edge, B2X apps); and Telco Cloud, Automation and Edge Compute platforms. This role also involves the integration of network systems and their operations, related to the above technologies.\\n\\nAbout The Role - Grade Specific\\nFocus on Connectivity and Network Engineering. Develops competency in own area of expertise. Shares expertise and provides guidance and support to others. Interprets clients needs. Completes own role independently or with minimum supervision. Identifies problems and relevant issues in straight forward situations and generates solutions. Contributes in teamwork and interacts with customers.',\n",
       " 'requirements': 'UG: Any Graduate, PG: Any Postgraduate, Key Skills: python, natural language processing, machine learning, iot, deep learning, c++, project management, software testing, plc, microsoft azure, artificial intelligence, sql, java, data science, predictive modeling, embedded systems, linux, embedded c, agile, aws',\n",
       " 'responsibilities': 'Focus on Connectivity and Network Engineering. Develops competency in own area of expertise. Shares expertise and provides guidance and support to others. Interprets clients needs. Completes own role independently or with minimum supervision. Identifies problems and relevant issues in straight forward situations and generates solutions. Contributes in teamwork and interacts with customers.',\n",
       " 'salary_range': 'Not Disclosed',\n",
       " 'posted_date': '4 days ago'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"================================================ JD ================================================\")\n",
    "job_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3466156",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = ResumeScorer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84195bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d6e59231714cf588866d1034583318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4abf62dcb0b34d558773fc063c01fb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7951026889e846109ff6d8422bc0569d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e630d2781c400ca8690d467a62107b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef64dd7e2b894c5a88354ed34c142857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cfe2631f27848b7aebc54a5709458c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0462f9381b22497e83b96259f008b8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274e551db7a34bfbace5e9292da90696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695446028cdb4532a4eedcf63e232e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6258979fd242a4b81690d6f10ca7fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'overall_score': 21.153300360934907,\n",
       " 'score_breakdown': {'semantic_similarity': 44.06804275512695,\n",
       "  'keyword_overlap': 9.090909090909092,\n",
       "  'tfidf_similarity': 3.9940526580569977,\n",
       "  'experience_match': 0.0},\n",
       " 'match_quality': 'Poor',\n",
       " 'model_used': 'all-roberta-large-v1-hybrid',\n",
       " 'recommendation': 'Consider updating resume with more relevant technical keywords'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = await scorer.score(resume_data, job_data)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad7e864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume-ats-score-checker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
